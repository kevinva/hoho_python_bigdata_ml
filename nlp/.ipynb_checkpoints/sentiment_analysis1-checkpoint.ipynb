{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10031b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fe26bc6bf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cd6ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19597</th>\n",
       "      <td>CBS Sports App - Scores, News, Stats &amp; Watch Live</td>\n",
       "      <td>Another thumbs latest update. Bring back My Sc...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476</th>\n",
       "      <td>AliExpress - Smarter Shopping, Better Living</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40979</th>\n",
       "      <td>Eve Period Tracker - Love, Sex &amp; Relationships...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9639</th>\n",
       "      <td>Avakin Life - 3D virtual world</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19803</th>\n",
       "      <td>CBS Sports Fantasy</td>\n",
       "      <td>I like helps fantasy football needs</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     App  \\\n",
       "19597  CBS Sports App - Scores, News, Stats & Watch Live   \n",
       "5476        AliExpress - Smarter Shopping, Better Living   \n",
       "40979  Eve Period Tracker - Love, Sex & Relationships...   \n",
       "9639                      Avakin Life - 3D virtual world   \n",
       "19803                                 CBS Sports Fantasy   \n",
       "\n",
       "                                       Translated_Review Sentiment  \\\n",
       "19597  Another thumbs latest update. Bring back My Sc...  Positive   \n",
       "5476                                                 NaN       NaN   \n",
       "40979                                                NaN       NaN   \n",
       "9639                                                 NaN       NaN   \n",
       "19803                I like helps fantasy football needs   Neutral   \n",
       "\n",
       "       Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "19597                0.25                    0.45  \n",
       "5476                  NaN                     NaN  \n",
       "40979                 NaN                     NaN  \n",
       "9639                  NaN                     NaN  \n",
       "19803                0.00                    0.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/googleplaystore_user_reviews.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724607a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64295, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21778fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37427, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5682cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment(rating):\n",
    "    if rating == 'Positive':\n",
    "        return 2\n",
    "    elif rating == 'Neutral':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124acefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df.Sentiment.apply(to_sentiment)\n",
    "\n",
    "class_names = ['Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95589f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    23998\n",
       "0     8271\n",
       "1     5158\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0374e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.1, random_state = RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size = 0.5, random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c911c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        target = self.targets[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens = True,\n",
    "            truncation=True,\n",
    "            max_length = self.max_len,\n",
    "            return_token_type_ids = False,\n",
    "            padding = 'max_length',\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt',\n",
    "            \n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype = torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbf10919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = GPReviewDataset(\n",
    "        reviews = df.Translated_Review.to_numpy(),\n",
    "        targets = df.sentiment.to_numpy(),\n",
    "        tokenizer = tokenizer,\n",
    "        max_len = max_len\n",
    "    )\n",
    "    return DataLoader(ds, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd02351",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 160\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e07dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p = 0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_output = self.bert(input_ids = input_ids, attention_mask = attention_mask)  # 第1个是loss\n",
    "#         print(f\"bert_out: {bert_output.last_hidden_state}\")\n",
    "#         print(f'last_hidden_state: {bert_output.last_hidden_state.size()}')\n",
    "#         print(f'pooler_output: {bert_output.pooler_output.size()}')\n",
    "#         print(f'input_ids: {input_ids.size()}')\n",
    "        first_token_tensor = bert_output.pooler_output\n",
    "        output = self.drop(first_token_tensor)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a74f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "D:\\ProgramData\\Anaconda3\\envs\\hoho_gym\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "EPOCHS = 10\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5, correct_bias = False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\n",
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f19a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for d in data_loader:\n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        targets = d['targets'].to(DEVICE)\n",
    "        \n",
    "        outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        _, preds = torch.max(outputs, dim = 1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        print(f'loss: {loss}')\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0dd620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48bd0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "----------\n",
      "loss: 1.0998482704162598\n",
      "loss: 1.0257536172866821\n",
      "loss: 0.8555214405059814\n",
      "loss: 1.0794246196746826\n",
      "loss: 0.8290035724639893\n",
      "loss: 1.1954704523086548\n",
      "loss: 0.9228551983833313\n",
      "loss: 0.932999312877655\n",
      "loss: 1.2336902618408203\n",
      "loss: 1.0865261554718018\n",
      "loss: 0.8022121787071228\n",
      "loss: 0.8710868954658508\n",
      "loss: 0.8731654286384583\n",
      "loss: 0.8886054754257202\n",
      "loss: 0.6363863945007324\n",
      "loss: 0.8209210634231567\n",
      "loss: 0.7745426893234253\n",
      "loss: 0.7188626527786255\n",
      "loss: 0.623023509979248\n",
      "loss: 0.514590322971344\n",
      "loss: 0.9388572573661804\n",
      "loss: 0.558646023273468\n",
      "loss: 0.4408569931983948\n",
      "loss: 0.46329036355018616\n",
      "loss: 0.5616952776908875\n",
      "loss: 0.7187432646751404\n",
      "loss: 0.6439228653907776\n",
      "loss: 0.6267889738082886\n",
      "loss: 0.6478189826011658\n",
      "loss: 0.6870012879371643\n",
      "loss: 0.776525616645813\n",
      "loss: 0.8739638328552246\n",
      "loss: 0.9963911771774292\n",
      "loss: 0.7910602688789368\n",
      "loss: 0.7546226382255554\n",
      "loss: 0.6884870529174805\n",
      "loss: 0.7469612956047058\n",
      "loss: 0.9563114643096924\n",
      "loss: 0.7594798803329468\n",
      "loss: 0.4944388270378113\n",
      "loss: 0.42388859391212463\n",
      "loss: 0.5149288177490234\n",
      "loss: 0.6192625761032104\n",
      "loss: 1.0041321516036987\n",
      "loss: 0.978984534740448\n",
      "loss: 0.8563883900642395\n",
      "loss: 0.8394837379455566\n",
      "loss: 0.6295768022537231\n",
      "loss: 0.8590275049209595\n",
      "loss: 0.8153766989707947\n",
      "loss: 0.7660501599311829\n",
      "loss: 0.751024067401886\n",
      "loss: 0.8366537094116211\n",
      "loss: 0.6551520228385925\n",
      "loss: 0.6759203672409058\n",
      "loss: 0.6032602190971375\n",
      "loss: 0.6346275806427002\n",
      "loss: 0.6282885670661926\n",
      "loss: 0.4390387237071991\n",
      "loss: 0.5680245757102966\n",
      "loss: 0.8593901991844177\n",
      "loss: 1.0229355096817017\n",
      "loss: 0.4793074429035187\n",
      "loss: 0.6319020390510559\n",
      "loss: 0.6336460113525391\n",
      "loss: 0.7076804637908936\n",
      "loss: 0.6611321568489075\n",
      "loss: 0.6110303997993469\n",
      "loss: 0.8238393068313599\n",
      "loss: 0.617708146572113\n",
      "loss: 0.4425576329231262\n",
      "loss: 0.5801756381988525\n",
      "loss: 0.6349915266036987\n",
      "loss: 0.7166689038276672\n",
      "loss: 0.4977160692214966\n",
      "loss: 0.6644085645675659\n",
      "loss: 0.5881118774414062\n",
      "loss: 0.8754020929336548\n",
      "loss: 0.49902087450027466\n",
      "loss: 0.4939378499984741\n",
      "loss: 0.45402801036834717\n",
      "loss: 0.9339780211448669\n",
      "loss: 0.47553467750549316\n",
      "loss: 0.5804510116577148\n",
      "loss: 0.5918758511543274\n",
      "loss: 0.31854692101478577\n",
      "loss: 0.47861847281455994\n",
      "loss: 0.6543418765068054\n",
      "loss: 0.6902438998222351\n",
      "loss: 0.47657594084739685\n",
      "loss: 0.7764192819595337\n",
      "loss: 0.4943786561489105\n",
      "loss: 0.5344746112823486\n",
      "loss: 0.43477103114128113\n",
      "loss: 0.7103782892227173\n",
      "loss: 0.4661363363265991\n",
      "loss: 0.7036706209182739\n",
      "loss: 0.48692619800567627\n",
      "loss: 0.5534645915031433\n",
      "loss: 0.663284182548523\n",
      "loss: 0.5986832976341248\n",
      "loss: 0.6249136328697205\n",
      "loss: 0.696883499622345\n",
      "loss: 0.7635722756385803\n",
      "loss: 0.3817012310028076\n",
      "loss: 0.6707316637039185\n",
      "loss: 0.6522755026817322\n",
      "loss: 0.6829285025596619\n",
      "loss: 0.6710307002067566\n",
      "loss: 0.8060899972915649\n",
      "loss: 0.5500143766403198\n",
      "loss: 0.6251407861709595\n",
      "loss: 0.667975127696991\n",
      "loss: 0.500332772731781\n",
      "loss: 0.47617247700691223\n",
      "loss: 0.66080641746521\n",
      "loss: 0.684537947177887\n",
      "loss: 0.5323777794837952\n",
      "loss: 0.7225341200828552\n",
      "loss: 0.837014377117157\n",
      "loss: 0.6609206795692444\n",
      "loss: 0.503692626953125\n",
      "loss: 0.4457770884037018\n",
      "loss: 0.6173479557037354\n",
      "loss: 0.5034978985786438\n",
      "loss: 0.3724820017814636\n",
      "loss: 0.4146268963813782\n",
      "loss: 0.3422791659832001\n",
      "loss: 0.6443163752555847\n",
      "loss: 0.6129094958305359\n",
      "loss: 0.5113689303398132\n",
      "loss: 0.5415874719619751\n",
      "loss: 0.48489856719970703\n",
      "loss: 0.5827302932739258\n",
      "loss: 0.5858968496322632\n",
      "loss: 0.28900396823883057\n",
      "loss: 0.6263413429260254\n",
      "loss: 0.7182573676109314\n",
      "loss: 0.6179614663124084\n",
      "loss: 0.5837485790252686\n",
      "loss: 0.7471824884414673\n",
      "loss: 0.4967348575592041\n",
      "loss: 0.5701720118522644\n",
      "loss: 0.6064023375511169\n",
      "loss: 0.5246689915657043\n",
      "loss: 0.4898381233215332\n",
      "loss: 0.4945543110370636\n",
      "loss: 0.6180005669593811\n",
      "loss: 0.5933417081832886\n",
      "loss: 0.465047687292099\n",
      "loss: 0.6810153722763062\n",
      "loss: 0.44037920236587524\n",
      "loss: 0.6859409809112549\n",
      "loss: 0.5696011781692505\n",
      "loss: 0.35546883940696716\n",
      "loss: 0.6920902132987976\n",
      "loss: 0.3311576247215271\n",
      "loss: 0.7265568971633911\n",
      "loss: 0.4149927794933319\n",
      "loss: 0.6037752628326416\n",
      "loss: 0.496217280626297\n",
      "loss: 0.37780988216400146\n",
      "loss: 0.5381385087966919\n",
      "loss: 0.32035741209983826\n",
      "loss: 0.5034166574478149\n",
      "loss: 0.680735170841217\n",
      "loss: 0.7043238878250122\n",
      "loss: 0.596686840057373\n",
      "loss: 0.6217616200447083\n",
      "loss: 0.5283452868461609\n",
      "loss: 0.5630940198898315\n",
      "loss: 0.5280349850654602\n",
      "loss: 0.46041154861450195\n",
      "loss: 0.15114514529705048\n",
      "loss: 0.5026497840881348\n",
      "loss: 0.6366525292396545\n",
      "loss: 0.4429998993873596\n",
      "loss: 0.5673595070838928\n",
      "loss: 0.6305082440376282\n",
      "loss: 0.2717933654785156\n",
      "loss: 0.4692758619785309\n",
      "loss: 0.3830523192882538\n",
      "loss: 0.305006206035614\n",
      "loss: 0.5785601139068604\n",
      "loss: 0.5193557739257812\n",
      "loss: 0.45394963026046753\n",
      "loss: 0.3260469138622284\n",
      "loss: 0.5304444432258606\n",
      "loss: 0.20056286454200745\n",
      "loss: 0.518035888671875\n",
      "loss: 0.4817045331001282\n",
      "loss: 0.7297711968421936\n",
      "loss: 0.5313147306442261\n",
      "loss: 0.6113222241401672\n",
      "loss: 0.8684895634651184\n",
      "loss: 0.3583025634288788\n",
      "loss: 0.6615462303161621\n",
      "loss: 0.34767287969589233\n",
      "loss: 0.7163816094398499\n",
      "loss: 0.5947790145874023\n",
      "loss: 0.4283830225467682\n",
      "loss: 0.45141780376434326\n",
      "loss: 0.3738304674625397\n",
      "loss: 0.5294905304908752\n",
      "loss: 0.4043397903442383\n",
      "loss: 0.4719003438949585\n",
      "loss: 0.14594803750514984\n",
      "loss: 0.8050181865692139\n",
      "loss: 0.36125391721725464\n",
      "loss: 0.5579075217247009\n",
      "loss: 0.20234768092632294\n",
      "loss: 0.34296029806137085\n",
      "loss: 0.5529426336288452\n",
      "loss: 0.4032610058784485\n",
      "loss: 0.3804488778114319\n",
      "loss: 0.6549861431121826\n",
      "loss: 0.31565818190574646\n",
      "loss: 0.3643711507320404\n",
      "loss: 0.7115505337715149\n",
      "loss: 0.48403996229171753\n",
      "loss: 0.3718739151954651\n",
      "loss: 0.5254075527191162\n",
      "loss: 0.4551023244857788\n",
      "loss: 0.7040141224861145\n",
      "loss: 0.5531527400016785\n",
      "loss: 0.1836506575345993\n",
      "loss: 0.6792992949485779\n",
      "loss: 0.5883805751800537\n",
      "loss: 0.46155229210853577\n",
      "loss: 0.6325938701629639\n",
      "loss: 0.6714224815368652\n",
      "loss: 0.3946303427219391\n",
      "loss: 0.5068714022636414\n",
      "loss: 0.4327011704444885\n",
      "loss: 0.5279774069786072\n",
      "loss: 0.3998095989227295\n",
      "loss: 0.5783224701881409\n",
      "loss: 0.9602925777435303\n",
      "loss: 0.4877215027809143\n",
      "loss: 0.36528095602989197\n",
      "loss: 0.33944305777549744\n",
      "loss: 0.21307115256786346\n",
      "loss: 0.3947080373764038\n",
      "loss: 0.22738704085350037\n",
      "loss: 0.4038476347923279\n",
      "loss: 0.48338034749031067\n",
      "loss: 0.5050928592681885\n",
      "loss: 0.2706158757209778\n",
      "loss: 0.39085885882377625\n",
      "loss: 0.6042489409446716\n",
      "loss: 0.331218421459198\n",
      "loss: 0.5037136077880859\n",
      "loss: 0.5207192897796631\n",
      "loss: 0.266190767288208\n",
      "loss: 0.40354374051094055\n",
      "loss: 0.5965061187744141\n",
      "loss: 0.5413473844528198\n",
      "loss: 0.4792555868625641\n",
      "loss: 0.26426440477371216\n",
      "loss: 0.2634115517139435\n",
      "loss: 0.30961793661117554\n",
      "loss: 0.5682356357574463\n",
      "loss: 0.4736018776893616\n",
      "loss: 0.6018489003181458\n",
      "loss: 0.5230414271354675\n",
      "loss: 0.28835466504096985\n",
      "loss: 0.28684669733047485\n",
      "loss: 0.5876677632331848\n",
      "loss: 0.35966068506240845\n",
      "loss: 0.39825454354286194\n",
      "loss: 0.24308528006076813\n",
      "loss: 0.2929305136203766\n",
      "loss: 0.23213699460029602\n",
      "loss: 0.5417993068695068\n",
      "loss: 0.4546296298503876\n",
      "loss: 0.4843459725379944\n",
      "loss: 0.5267616510391235\n",
      "loss: 0.5722058415412903\n",
      "loss: 0.6081387996673584\n",
      "loss: 0.7790519595146179\n",
      "loss: 0.4208909571170807\n",
      "loss: 0.5482670664787292\n",
      "loss: 0.48485493659973145\n",
      "loss: 0.6626951694488525\n",
      "loss: 0.517198383808136\n",
      "loss: 0.4948272705078125\n",
      "loss: 0.49553579092025757\n",
      "loss: 0.3146408796310425\n",
      "loss: 0.878105640411377\n",
      "loss: 0.31067121028900146\n",
      "loss: 0.4994083046913147\n",
      "loss: 0.48338985443115234\n",
      "loss: 0.3596023917198181\n",
      "loss: 0.3892618417739868\n",
      "loss: 0.3017875552177429\n",
      "loss: 0.29042837023735046\n",
      "loss: 0.447891503572464\n",
      "loss: 0.4422793686389923\n",
      "loss: 0.29769542813301086\n",
      "loss: 0.3495641350746155\n",
      "loss: 0.3154889941215515\n",
      "loss: 0.3419100344181061\n",
      "loss: 0.33530744910240173\n",
      "loss: 0.15472985804080963\n",
      "loss: 0.33230096101760864\n",
      "loss: 0.13355474174022675\n",
      "loss: 1.1282833814620972\n",
      "loss: 0.29107916355133057\n",
      "loss: 0.5047129988670349\n",
      "loss: 0.2595309615135193\n",
      "loss: 0.4045726954936981\n",
      "loss: 0.5043768882751465\n",
      "loss: 0.5860174894332886\n",
      "loss: 0.7001749873161316\n",
      "loss: 0.46373340487480164\n",
      "loss: 0.3752165734767914\n",
      "loss: 0.4904950261116028\n",
      "loss: 0.6062955260276794\n",
      "loss: 0.4712564945220947\n",
      "loss: 0.5539908409118652\n",
      "loss: 0.4866028130054474\n",
      "loss: 0.5413734316825867\n",
      "loss: 0.7076320052146912\n",
      "loss: 0.30804678797721863\n",
      "loss: 0.45341169834136963\n",
      "loss: 0.33758479356765747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.37872254848480225\n",
      "loss: 0.40130415558815\n",
      "loss: 0.17757554352283478\n",
      "loss: 0.3654423952102661\n",
      "loss: 0.2542516887187958\n",
      "loss: 0.234462171792984\n",
      "loss: 0.2518489956855774\n",
      "loss: 0.24082051217556\n",
      "loss: 0.8012966513633728\n",
      "loss: 0.37354370951652527\n",
      "loss: 0.20881789922714233\n",
      "loss: 0.362024188041687\n",
      "loss: 0.4565296173095703\n",
      "loss: 0.1774483174085617\n",
      "loss: 0.6393144726753235\n",
      "loss: 0.4533521234989166\n",
      "loss: 0.4030841290950775\n",
      "loss: 0.39387187361717224\n",
      "loss: 0.31110256910324097\n",
      "loss: 0.49345630407333374\n",
      "loss: 0.32125985622406006\n",
      "loss: 0.5770620107650757\n",
      "loss: 0.3079553544521332\n",
      "loss: 0.30774471163749695\n",
      "loss: 0.5273316502571106\n",
      "loss: 0.4616997539997101\n",
      "loss: 0.2671037018299103\n",
      "loss: 0.126154825091362\n",
      "loss: 0.32338041067123413\n",
      "loss: 0.345729261636734\n",
      "loss: 0.565685510635376\n",
      "loss: 0.46108904480934143\n",
      "loss: 0.4002176523208618\n",
      "loss: 0.48269960284233093\n",
      "loss: 0.2812097668647766\n",
      "loss: 0.4920036792755127\n",
      "loss: 0.3341120779514313\n",
      "loss: 0.3091096878051758\n",
      "loss: 0.3228503465652466\n",
      "loss: 0.4049369990825653\n",
      "loss: 0.344983845949173\n",
      "loss: 0.3478908836841583\n",
      "loss: 0.35076409578323364\n",
      "loss: 0.6401295065879822\n",
      "loss: 0.3527704179286957\n",
      "loss: 0.2628073990345001\n",
      "loss: 0.3482094407081604\n",
      "loss: 0.48083391785621643\n",
      "loss: 0.48688244819641113\n",
      "loss: 0.4391361474990845\n",
      "loss: 0.49221232533454895\n",
      "loss: 0.45993128418922424\n",
      "loss: 0.5487892627716064\n",
      "loss: 0.19863179326057434\n",
      "loss: 0.542485773563385\n",
      "loss: 0.3447171747684479\n",
      "loss: 0.5146856307983398\n",
      "loss: 0.16475829482078552\n",
      "loss: 0.36757805943489075\n",
      "loss: 0.23309411108493805\n",
      "loss: 0.53993821144104\n",
      "loss: 0.43514135479927063\n",
      "loss: 0.5452519655227661\n",
      "loss: 0.2527765929698944\n",
      "loss: 0.4898199141025543\n",
      "loss: 0.2808999717235565\n",
      "loss: 0.5800776481628418\n",
      "loss: 0.5594508647918701\n",
      "loss: 0.22687435150146484\n",
      "loss: 0.2307395488023758\n",
      "loss: 0.18370284140110016\n",
      "loss: 0.3110823333263397\n",
      "loss: 0.6808723211288452\n",
      "loss: 0.29822203516960144\n",
      "loss: 0.13680100440979004\n",
      "loss: 0.06487929821014404\n",
      "loss: 0.42789462208747864\n",
      "loss: 0.28255075216293335\n",
      "loss: 0.3857845962047577\n",
      "loss: 0.25975513458251953\n",
      "loss: 0.8045772314071655\n",
      "loss: 0.3639162480831146\n",
      "loss: 0.10486853867769241\n",
      "loss: 0.28829941153526306\n",
      "loss: 0.1280692219734192\n",
      "loss: 0.4069986939430237\n",
      "loss: 0.3786868453025818\n",
      "loss: 0.21662628650665283\n",
      "loss: 0.18369698524475098\n",
      "loss: 0.0249934084713459\n",
      "loss: 0.5940220952033997\n",
      "loss: 0.4245629906654358\n",
      "loss: 0.4029079079627991\n",
      "loss: 0.6084508895874023\n",
      "loss: 0.3919830918312073\n",
      "loss: 0.260027140378952\n",
      "loss: 0.4351523816585541\n",
      "loss: 0.35706841945648193\n",
      "loss: 0.28034594655036926\n",
      "loss: 0.18949007987976074\n",
      "loss: 0.5331414937973022\n",
      "loss: 0.23962031304836273\n",
      "loss: 0.3024442195892334\n",
      "loss: 0.5769465565681458\n",
      "loss: 0.22808097302913666\n",
      "loss: 0.13498806953430176\n",
      "loss: 0.24902509152889252\n",
      "loss: 0.23546671867370605\n",
      "loss: 0.2748701572418213\n",
      "loss: 0.5089234709739685\n",
      "loss: 0.29744359850883484\n",
      "loss: 0.2474324256181717\n",
      "loss: 0.28679344058036804\n",
      "loss: 0.09102723747491837\n",
      "loss: 0.353867769241333\n",
      "loss: 0.39357492327690125\n",
      "loss: 0.13052919507026672\n",
      "loss: 0.6423323750495911\n",
      "loss: 0.47810274362564087\n",
      "loss: 0.34405526518821716\n",
      "loss: 0.2810906767845154\n",
      "loss: 0.45503950119018555\n",
      "loss: 0.2706134617328644\n",
      "loss: 0.11068844795227051\n",
      "loss: 0.3561243712902069\n",
      "loss: 0.2842615246772766\n",
      "loss: 0.2606654167175293\n",
      "loss: 0.42665693163871765\n",
      "loss: 0.1827646642923355\n",
      "loss: 0.47220945358276367\n",
      "loss: 0.22047306597232819\n",
      "loss: 0.32044869661331177\n",
      "loss: 0.4392125904560089\n",
      "loss: 0.3147713840007782\n",
      "loss: 0.29148152470588684\n",
      "loss: 0.5084218382835388\n",
      "loss: 0.1589343547821045\n",
      "loss: 0.37310680747032166\n",
      "loss: 0.5329350829124451\n",
      "loss: 0.07567638158798218\n",
      "loss: 0.18738844990730286\n",
      "loss: 0.25069957971572876\n",
      "loss: 0.1076849028468132\n",
      "loss: 0.3065383732318878\n",
      "loss: 0.15507186949253082\n",
      "loss: 0.42689263820648193\n",
      "loss: 0.32602328062057495\n",
      "loss: 0.24158601462841034\n",
      "loss: 0.2367572784423828\n",
      "loss: 0.49554678797721863\n",
      "loss: 0.294357031583786\n",
      "loss: 0.27598515152931213\n",
      "loss: 0.22399340569972992\n",
      "loss: 0.27795785665512085\n",
      "loss: 0.08668781071901321\n",
      "loss: 0.41563403606414795\n",
      "loss: 0.2854301333427429\n",
      "loss: 0.07508242875337601\n",
      "loss: 0.41352659463882446\n",
      "loss: 0.32996976375579834\n",
      "loss: 0.2985572814941406\n",
      "loss: 0.30923348665237427\n",
      "loss: 0.4855178892612457\n",
      "loss: 0.30962303280830383\n",
      "loss: 0.3015960454940796\n",
      "loss: 0.19785118103027344\n",
      "loss: 0.24335075914859772\n",
      "loss: 0.3461032807826996\n",
      "loss: 0.2881605923175812\n",
      "loss: 0.570178210735321\n",
      "loss: 0.4537183940410614\n",
      "loss: 0.18018651008605957\n",
      "loss: 0.3227274417877197\n",
      "loss: 0.4197472929954529\n",
      "loss: 0.3268248438835144\n",
      "loss: 0.2771621644496918\n",
      "loss: 0.3713337481021881\n",
      "loss: 0.22659480571746826\n",
      "loss: 0.672584056854248\n",
      "loss: 0.42824888229370117\n",
      "loss: 0.2198992818593979\n",
      "loss: 0.33547526597976685\n",
      "loss: 0.2753118872642517\n",
      "loss: 0.347922146320343\n",
      "loss: 0.2413935661315918\n",
      "loss: 0.3600769340991974\n",
      "loss: 0.3834432363510132\n",
      "loss: 0.4706070125102997\n",
      "loss: 0.15604132413864136\n",
      "loss: 0.091068334877491\n",
      "loss: 0.26876580715179443\n",
      "loss: 0.27650728821754456\n",
      "loss: 0.0962897539138794\n",
      "loss: 0.21699129045009613\n",
      "loss: 0.42319297790527344\n",
      "loss: 0.48647016286849976\n",
      "loss: 0.13942673802375793\n",
      "loss: 0.3795012831687927\n",
      "loss: 0.249810129404068\n",
      "loss: 0.15705201029777527\n",
      "loss: 0.2896278202533722\n",
      "loss: 0.4908103942871094\n",
      "loss: 0.4497794210910797\n",
      "loss: 0.3315970301628113\n",
      "loss: 0.271441787481308\n",
      "loss: 0.4123225510120392\n",
      "loss: 0.12159612774848938\n",
      "loss: 0.4241805076599121\n",
      "loss: 0.2297002226114273\n",
      "loss: 0.2481282651424408\n",
      "loss: 0.13498231768608093\n",
      "loss: 0.5704073905944824\n",
      "loss: 0.3072347640991211\n",
      "loss: 0.10301817953586578\n",
      "loss: 0.12838876247406006\n",
      "loss: 0.3343440890312195\n",
      "loss: 0.3303872048854828\n",
      "loss: 0.4824833869934082\n",
      "loss: 0.2791236340999603\n",
      "loss: 0.2775510251522064\n",
      "loss: 0.2171206921339035\n",
      "loss: 0.23256026208400726\n",
      "loss: 0.275616317987442\n",
      "loss: 0.3357503116130829\n",
      "loss: 0.25569838285446167\n",
      "loss: 0.26939889788627625\n",
      "loss: 0.4661344289779663\n",
      "loss: 0.1210537701845169\n",
      "loss: 0.3756546676158905\n",
      "loss: 0.2651066482067108\n",
      "loss: 0.32396385073661804\n",
      "loss: 0.35075268149375916\n",
      "loss: 0.33373987674713135\n",
      "loss: 0.30297496914863586\n",
      "loss: 0.3484134376049042\n",
      "loss: 0.4439806044101715\n",
      "loss: 0.118716299533844\n",
      "loss: 0.1173572689294815\n",
      "loss: 0.09068679809570312\n",
      "loss: 0.16725675761699677\n",
      "loss: 0.15622980892658234\n",
      "loss: 0.3229282796382904\n",
      "loss: 0.3979778587818146\n",
      "loss: 0.30097272992134094\n",
      "loss: 0.05274774879217148\n",
      "loss: 0.23137395083904266\n",
      "loss: 0.8159459233283997\n",
      "loss: 0.4134678542613983\n",
      "loss: 0.16492155194282532\n",
      "loss: 0.5238770842552185\n",
      "loss: 0.1301584392786026\n",
      "loss: 0.4117860794067383\n",
      "loss: 0.5186070799827576\n",
      "loss: 0.591376543045044\n",
      "loss: 0.29674363136291504\n",
      "loss: 0.3782086968421936\n",
      "loss: 0.17421922087669373\n",
      "loss: 0.04669789969921112\n",
      "loss: 0.21632599830627441\n",
      "loss: 0.4615401029586792\n",
      "loss: 0.04626746103167534\n",
      "loss: 0.2566430866718292\n",
      "loss: 0.5866753458976746\n",
      "loss: 0.40610596537590027\n",
      "loss: 0.2071963995695114\n",
      "loss: 0.26611682772636414\n",
      "loss: 0.39082562923431396\n",
      "loss: 0.5451624393463135\n",
      "loss: 0.5313003063201904\n",
      "loss: 0.1507054567337036\n",
      "loss: 0.36283251643180847\n",
      "loss: 0.2914664149284363\n",
      "loss: 0.5249444842338562\n",
      "loss: 0.3815378248691559\n",
      "loss: 0.5230011343955994\n",
      "loss: 0.11728280037641525\n",
      "loss: 0.5934762954711914\n",
      "loss: 0.3213962912559509\n",
      "loss: 0.1826193928718567\n",
      "loss: 0.25586625933647156\n",
      "loss: 0.23193182051181793\n",
      "loss: 0.5565739870071411\n",
      "loss: 0.1843816637992859\n",
      "loss: 0.3681175708770752\n",
      "loss: 0.11924158781766891\n",
      "loss: 0.15962830185890198\n",
      "loss: 0.12762220203876495\n",
      "loss: 0.13191412389278412\n",
      "loss: 0.3335613012313843\n",
      "loss: 0.5971090197563171\n",
      "loss: 0.4421009123325348\n",
      "loss: 0.2745082378387451\n",
      "loss: 0.5209677219390869\n",
      "loss: 0.27794474363327026\n",
      "loss: 0.24756313860416412\n",
      "loss: 0.31702205538749695\n",
      "loss: 0.15165935456752777\n",
      "loss: 0.10553743690252304\n",
      "loss: 0.529422402381897\n",
      "loss: 0.49031320214271545\n",
      "loss: 0.26076969504356384\n",
      "loss: 0.057303957641124725\n",
      "loss: 0.1644890010356903\n",
      "loss: 0.3822988271713257\n",
      "loss: 0.2879796624183655\n",
      "loss: 0.23646636307239532\n",
      "loss: 0.23622053861618042\n",
      "loss: 0.42051130533218384\n",
      "loss: 0.30608001351356506\n",
      "loss: 0.4592970907688141\n",
      "loss: 0.11986996233463287\n",
      "loss: 0.2799501419067383\n",
      "loss: 0.2081933170557022\n",
      "loss: 0.17346617579460144\n",
      "loss: 0.12786172330379486\n",
      "loss: 0.2833169996738434\n",
      "loss: 0.32104790210723877\n",
      "loss: 0.1933659017086029\n",
      "loss: 0.1994958072900772\n",
      "loss: 0.5711069107055664\n",
      "loss: 0.19920426607131958\n",
      "loss: 0.13592198491096497\n",
      "loss: 0.09543564915657043\n",
      "loss: 0.2269311398267746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5118144750595093\n",
      "loss: 0.28045228123664856\n",
      "loss: 0.3010563254356384\n",
      "loss: 0.5638068318367004\n",
      "loss: 0.3730457127094269\n",
      "loss: 0.32644888758659363\n",
      "loss: 0.48367175459861755\n",
      "loss: 0.26214277744293213\n",
      "loss: 0.10099417716264725\n",
      "loss: 0.23013441264629364\n",
      "loss: 0.24648432433605194\n",
      "loss: 0.1591026484966278\n",
      "loss: 0.5429048538208008\n",
      "loss: 0.46341872215270996\n",
      "loss: 0.5609012842178345\n",
      "loss: 0.17978313565254211\n",
      "loss: 0.3208411931991577\n",
      "loss: 0.1816805750131607\n",
      "loss: 0.25484800338745117\n",
      "loss: 0.5447784662246704\n",
      "loss: 0.2510116994380951\n",
      "loss: 0.14974543452262878\n",
      "loss: 0.311143696308136\n",
      "loss: 0.26976948976516724\n",
      "loss: 0.2073831409215927\n",
      "loss: 0.2715219557285309\n",
      "loss: 0.2183004468679428\n",
      "loss: 0.47295045852661133\n",
      "loss: 0.11962057650089264\n",
      "loss: 0.3567597568035126\n",
      "loss: 0.31401410698890686\n",
      "loss: 0.08785401284694672\n",
      "loss: 0.9298037886619568\n",
      "loss: 0.1893470138311386\n",
      "loss: 0.24222244322299957\n",
      "loss: 0.6867036819458008\n",
      "loss: 0.5730746388435364\n",
      "loss: 0.0911240354180336\n",
      "loss: 0.39112746715545654\n",
      "loss: 0.440239816904068\n",
      "loss: 0.2340191900730133\n",
      "loss: 0.25171059370040894\n",
      "loss: 0.2903871536254883\n",
      "loss: 0.2848568558692932\n",
      "loss: 0.5940825343132019\n",
      "loss: 0.38389265537261963\n",
      "loss: 0.30333366990089417\n",
      "loss: 0.18564832210540771\n",
      "loss: 0.32113343477249146\n",
      "loss: 0.5656189918518066\n",
      "loss: 0.29846084117889404\n",
      "loss: 0.34544557332992554\n",
      "loss: 0.13137711584568024\n",
      "loss: 0.5322155356407166\n",
      "loss: 0.3318287134170532\n",
      "loss: 0.18621566891670227\n",
      "loss: 0.2801046669483185\n",
      "loss: 0.34519079327583313\n",
      "loss: 0.15791624784469604\n",
      "loss: 0.20705477893352509\n",
      "loss: 0.2826717793941498\n",
      "loss: 0.3587634265422821\n",
      "loss: 0.08799654990434647\n",
      "loss: 0.3938632905483246\n",
      "loss: 0.3838741183280945\n",
      "loss: 0.1548624336719513\n",
      "loss: 0.3009941279888153\n",
      "loss: 0.19762180745601654\n",
      "loss: 0.6195274591445923\n",
      "loss: 0.4454011619091034\n",
      "loss: 0.25720757246017456\n",
      "loss: 0.2203732281923294\n",
      "loss: 0.16885344684123993\n",
      "loss: 0.27967169880867004\n",
      "loss: 0.4183809161186218\n",
      "loss: 0.17875276505947113\n",
      "loss: 0.33296656608581543\n",
      "loss: 0.1796015501022339\n",
      "loss: 0.14246197044849396\n",
      "loss: 0.15929363667964935\n",
      "loss: 0.1341865062713623\n",
      "loss: 0.3945954740047455\n",
      "loss: 0.3947626054286957\n",
      "loss: 0.15982180833816528\n",
      "loss: 0.05237177014350891\n",
      "loss: 0.20167513191699982\n",
      "loss: 0.052566081285476685\n",
      "loss: 0.508304238319397\n",
      "loss: 0.20631414651870728\n",
      "loss: 0.17199131846427917\n",
      "loss: 0.21908830106258392\n",
      "loss: 0.3919563591480255\n",
      "loss: 0.43287333846092224\n",
      "loss: 0.26795488595962524\n",
      "loss: 0.3106805086135864\n",
      "loss: 0.08567602187395096\n",
      "loss: 0.3371247947216034\n",
      "loss: 0.05475978925824165\n",
      "loss: 0.44808638095855713\n",
      "loss: 0.22274261713027954\n",
      "loss: 0.3980594277381897\n",
      "loss: 0.1735999435186386\n",
      "loss: 0.060903407633304596\n",
      "loss: 0.11547571420669556\n",
      "loss: 0.1551467478275299\n",
      "loss: 0.4147956967353821\n",
      "loss: 0.2596905827522278\n",
      "loss: 0.20535188913345337\n",
      "loss: 0.15372271835803986\n",
      "loss: 0.4025055170059204\n",
      "loss: 0.04105529189109802\n",
      "loss: 0.28585824370384216\n",
      "loss: 0.19997794926166534\n",
      "loss: 0.15829122066497803\n",
      "loss: 0.238565132021904\n",
      "loss: 0.4736500382423401\n",
      "loss: 0.049957457929849625\n",
      "loss: 0.11645195633172989\n",
      "loss: 0.21910539269447327\n",
      "loss: 0.3815186321735382\n",
      "loss: 0.3232963979244232\n",
      "loss: 0.43505966663360596\n",
      "loss: 0.2498328536748886\n",
      "loss: 0.37963631749153137\n",
      "loss: 0.08814604580402374\n",
      "loss: 0.1673678159713745\n",
      "loss: 0.14952348172664642\n",
      "loss: 0.29084861278533936\n",
      "loss: 0.13606643676757812\n",
      "loss: 0.09810629487037659\n",
      "loss: 0.2443505823612213\n",
      "loss: 0.6467688083648682\n",
      "loss: 0.22761742770671844\n",
      "loss: 0.12802544236183167\n",
      "loss: 0.4793699085712433\n",
      "loss: 0.13449551165103912\n",
      "loss: 0.09487210959196091\n",
      "loss: 0.13058380782604218\n",
      "loss: 0.09279899299144745\n",
      "loss: 0.2253272980451584\n",
      "loss: 0.21298032999038696\n",
      "loss: 0.07268655300140381\n",
      "loss: 0.10317578166723251\n",
      "loss: 0.28780993819236755\n",
      "loss: 0.7360472083091736\n",
      "loss: 0.08173546195030212\n",
      "loss: 0.710525631904602\n",
      "loss: 0.3288893699645996\n",
      "loss: 0.1155606061220169\n",
      "loss: 0.48559287190437317\n",
      "loss: 0.22471162676811218\n",
      "loss: 0.33808422088623047\n",
      "loss: 0.4223901629447937\n",
      "loss: 0.22596576809883118\n",
      "loss: 0.2557843029499054\n",
      "loss: 0.4022601246833801\n",
      "loss: 0.1445523202419281\n",
      "loss: 0.10698262602090836\n",
      "loss: 0.08117752522230148\n",
      "loss: 0.5057745575904846\n",
      "loss: 0.14170336723327637\n",
      "loss: 0.0602174811065197\n",
      "loss: 0.2580451965332031\n",
      "loss: 0.19892872869968414\n",
      "loss: 0.3593810200691223\n",
      "loss: 0.18349410593509674\n",
      "loss: 0.05078987032175064\n",
      "loss: 0.314823716878891\n",
      "loss: 0.05535047501325607\n",
      "loss: 0.02445865049958229\n",
      "loss: 0.1396070420742035\n",
      "loss: 0.2110925167798996\n",
      "loss: 0.23922140896320343\n",
      "loss: 0.1282162219285965\n",
      "loss: 0.38571035861968994\n",
      "loss: 0.168920636177063\n",
      "loss: 0.2412521243095398\n",
      "loss: 0.2594342827796936\n",
      "loss: 0.35199132561683655\n",
      "loss: 0.3624486029148102\n",
      "loss: 0.5226132869720459\n",
      "loss: 0.2789689600467682\n",
      "loss: 0.3406848609447479\n",
      "loss: 0.08100105822086334\n",
      "loss: 0.06204932555556297\n",
      "loss: 0.2937151789665222\n",
      "loss: 0.20162934064865112\n",
      "loss: 0.2614254057407379\n",
      "loss: 0.18080562353134155\n",
      "loss: 0.15793941915035248\n",
      "loss: 0.3220698833465576\n",
      "loss: 0.2136213481426239\n",
      "loss: 0.08096619695425034\n",
      "loss: 0.21779850125312805\n",
      "loss: 0.12867110967636108\n",
      "loss: 0.22625690698623657\n",
      "loss: 0.26492172479629517\n",
      "loss: 0.1856672465801239\n",
      "loss: 0.36116230487823486\n",
      "loss: 0.21605534851551056\n",
      "loss: 0.20095662772655487\n",
      "loss: 0.4495718777179718\n",
      "loss: 0.130095973610878\n",
      "loss: 0.30091434717178345\n",
      "loss: 0.2075214684009552\n",
      "loss: 0.23352797329425812\n",
      "loss: 0.352190762758255\n",
      "loss: 0.2804982364177704\n",
      "loss: 0.34704166650772095\n",
      "loss: 0.2398553490638733\n",
      "loss: 0.1833627074956894\n",
      "loss: 0.25830984115600586\n",
      "loss: 0.3616843521595001\n",
      "loss: 0.1413021981716156\n",
      "loss: 0.14782017469406128\n",
      "loss: 0.13230109214782715\n",
      "loss: 0.22754569351673126\n",
      "loss: 0.19083286821842194\n",
      "loss: 0.1114177331328392\n",
      "loss: 0.26463061571121216\n",
      "loss: 0.04018601402640343\n",
      "loss: 0.08849871903657913\n",
      "loss: 0.36813151836395264\n",
      "loss: 0.7536677718162537\n",
      "loss: 0.09806866198778152\n",
      "loss: 0.2300417125225067\n",
      "loss: 0.06789755076169968\n",
      "loss: 0.2820933759212494\n",
      "loss: 0.29436755180358887\n",
      "loss: 0.33797961473464966\n",
      "loss: 0.38535913825035095\n",
      "loss: 0.4695781171321869\n",
      "loss: 0.11903554946184158\n",
      "loss: 0.45095095038414\n",
      "loss: 0.159735307097435\n",
      "loss: 0.31601959466934204\n",
      "loss: 0.10720691829919815\n",
      "loss: 0.4806142747402191\n",
      "loss: 0.3177414536476135\n",
      "loss: 0.24655327200889587\n",
      "loss: 0.5115011930465698\n",
      "loss: 0.14562293887138367\n",
      "loss: 0.3345298767089844\n",
      "loss: 0.17755217850208282\n",
      "loss: 0.5257078409194946\n",
      "loss: 0.1069783940911293\n",
      "loss: 0.16316094994544983\n",
      "loss: 0.19807569682598114\n",
      "loss: 0.18979887664318085\n",
      "loss: 0.2047298550605774\n",
      "loss: 0.25675496459007263\n",
      "loss: 0.18584346771240234\n",
      "loss: 0.25582900643348694\n",
      "loss: 0.3082321584224701\n",
      "loss: 0.14129118621349335\n",
      "loss: 0.28569716215133667\n",
      "loss: 0.18440444767475128\n",
      "loss: 0.42774203419685364\n",
      "loss: 0.18360503017902374\n",
      "loss: 0.11377526819705963\n",
      "loss: 0.25801271200180054\n",
      "loss: 0.3406466841697693\n",
      "loss: 0.1726556420326233\n",
      "loss: 0.19184014201164246\n",
      "loss: 0.39560946822166443\n",
      "loss: 0.2774346172809601\n",
      "loss: 0.08560046553611755\n",
      "loss: 0.3105708360671997\n",
      "loss: 0.2242511510848999\n",
      "loss: 0.08018595725297928\n",
      "loss: 0.45264461636543274\n",
      "loss: 0.16555505990982056\n",
      "loss: 0.1601117104291916\n",
      "loss: 0.10993985831737518\n",
      "loss: 0.12766550481319427\n",
      "loss: 0.33542177081108093\n",
      "loss: 0.560275673866272\n",
      "loss: 0.1785297840833664\n",
      "loss: 0.2971358895301819\n",
      "loss: 0.3370658755302429\n",
      "loss: 0.19373401999473572\n",
      "loss: 0.040445636957883835\n",
      "loss: 0.24341905117034912\n",
      "loss: 0.2367236316204071\n",
      "loss: 0.22532008588314056\n",
      "loss: 0.08875780552625656\n",
      "loss: 0.18788649141788483\n",
      "loss: 0.4115108847618103\n",
      "loss: 0.11180611699819565\n",
      "loss: 0.26067379117012024\n",
      "loss: 0.16544879972934723\n",
      "loss: 0.3403994143009186\n",
      "loss: 0.24261155724525452\n",
      "loss: 0.3684730529785156\n",
      "loss: 0.364872008562088\n",
      "loss: 0.27431198954582214\n",
      "loss: 0.4398948848247528\n",
      "loss: 0.21566417813301086\n",
      "loss: 0.3031942844390869\n",
      "loss: 0.21772414445877075\n",
      "loss: 0.18752557039260864\n",
      "loss: 0.23612210154533386\n",
      "loss: 0.3209920823574066\n",
      "loss: 0.16812275350093842\n",
      "loss: 0.24441160261631012\n",
      "loss: 0.3801524341106415\n",
      "loss: 0.15238410234451294\n",
      "loss: 0.1217438131570816\n",
      "loss: 0.22048527002334595\n",
      "loss: 0.2495574802160263\n",
      "loss: 0.07145994156599045\n",
      "loss: 0.20760004222393036\n",
      "loss: 0.3087010681629181\n",
      "loss: 0.16900242865085602\n",
      "loss: 0.3660230040550232\n",
      "loss: 0.14437076449394226\n",
      "loss: 0.038585446774959564\n",
      "loss: 0.09391722828149796\n",
      "loss: 0.2925911843776703\n",
      "loss: 0.0564013235270977\n",
      "loss: 0.08251297473907471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.20863237977027893\n",
      "loss: 0.46015414595603943\n",
      "loss: 0.3810824155807495\n",
      "loss: 0.3067469894886017\n",
      "loss: 0.4376849830150604\n",
      "loss: 0.09203136712312698\n",
      "loss: 0.38371723890304565\n",
      "loss: 0.3144679367542267\n",
      "loss: 0.056572262197732925\n",
      "loss: 0.26599428057670593\n",
      "loss: 0.22117403149604797\n",
      "loss: 0.038384970277547836\n",
      "loss: 0.46516862511634827\n",
      "loss: 0.23790960013866425\n",
      "loss: 0.6048957109451294\n",
      "loss: 0.2064603567123413\n",
      "loss: 0.06574566662311554\n",
      "loss: 0.24415719509124756\n",
      "loss: 0.07812011241912842\n",
      "loss: 0.07763116806745529\n",
      "loss: 0.48888421058654785\n",
      "loss: 0.3533344268798828\n",
      "loss: 0.23894521594047546\n",
      "loss: 0.24710267782211304\n",
      "loss: 0.19971421360969543\n",
      "loss: 0.23147860169410706\n",
      "loss: 0.6027262806892395\n",
      "loss: 0.2758195102214813\n",
      "loss: 0.15562167763710022\n",
      "loss: 0.13099297881126404\n",
      "loss: 0.12305864691734314\n",
      "loss: 0.15066266059875488\n",
      "loss: 0.043217603117227554\n",
      "loss: 0.4766846299171448\n",
      "loss: 0.6068283915519714\n",
      "loss: 0.3966781198978424\n",
      "loss: 0.31823211908340454\n",
      "loss: 0.06393805146217346\n",
      "loss: 0.34601423144340515\n",
      "loss: 0.3698808550834656\n",
      "loss: 0.19733008742332458\n",
      "loss: 0.18609116971492767\n",
      "loss: 0.1238422691822052\n",
      "loss: 0.23340195417404175\n",
      "loss: 0.3657732605934143\n",
      "loss: 0.5832012295722961\n",
      "loss: 0.12575475871562958\n",
      "loss: 0.15754535794258118\n",
      "loss: 0.1491374671459198\n",
      "loss: 0.20200787484645844\n",
      "loss: 0.11810698360204697\n",
      "loss: 0.26510563492774963\n",
      "loss: 0.2936655580997467\n",
      "loss: 0.12431082129478455\n",
      "loss: 0.15774653851985931\n",
      "loss: 0.2311829924583435\n",
      "loss: 0.13323016464710236\n",
      "loss: 0.2310725301504135\n",
      "loss: 0.15779805183410645\n",
      "loss: 0.10027232766151428\n",
      "loss: 0.136137455701828\n",
      "loss: 0.2697655260562897\n",
      "loss: 0.31065744161605835\n",
      "loss: 0.2586301565170288\n",
      "loss: 0.25900885462760925\n",
      "loss: 0.11636258661746979\n",
      "loss: 0.23117657005786896\n",
      "loss: 0.1922438144683838\n",
      "loss: 0.21535111963748932\n",
      "loss: 0.17268866300582886\n",
      "loss: 0.16804638504981995\n",
      "loss: 0.11528081446886063\n",
      "loss: 0.07361559569835663\n",
      "loss: 0.2378043830394745\n",
      "loss: 0.5166357159614563\n",
      "loss: 0.46839454770088196\n",
      "loss: 0.18392999470233917\n",
      "loss: 0.2546648681163788\n",
      "loss: 0.36806052923202515\n",
      "loss: 0.31933799386024475\n",
      "loss: 0.18965940177440643\n",
      "loss: 0.11304247379302979\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'correct_prredictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m val_acc, val_loss \u001b[38;5;241m=\u001b[39m eval_model(\n\u001b[0;32m     20\u001b[0m     model,\n\u001b[0;32m     21\u001b[0m     val_data_loader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mlen\u001b[39m(df_val)\n\u001b[0;32m     25\u001b[0m )\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[0;32m     23\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrect_prredictions\u001b[49m\u001b[38;5;241m.\u001b[39mdouble() \u001b[38;5;241m/\u001b[39m n_examples, np\u001b[38;5;241m.\u001b[39mmean(losses)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'correct_prredictions' is not defined"
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1} / {EPOCHS}')\n",
    "    print('-' * 10)\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        DEVICE,\n",
    "        scheduler,\n",
    "        len(df_train)\n",
    "    )\n",
    "    \n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "    \n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        DEVICE,\n",
    "        len(df_val)\n",
    "    )\n",
    "    \n",
    "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "    \n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), './output/best_model_state_sentiment_analysis.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978c16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e86cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
