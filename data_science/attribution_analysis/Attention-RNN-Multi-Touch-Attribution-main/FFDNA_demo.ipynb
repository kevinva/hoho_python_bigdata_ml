{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc22824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve,confusion_matrix,f1_score, roc_auc_score\n",
    "from keras.layers import Concatenate, Dot, Input, LSTM\n",
    "from keras.layers import RepeatVector, Dense, Activation\n",
    "from keras.layers import Reshape, Dropout, Add, Subtract, Flatten, Embedding\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from process_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0814316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFDNA(object):\n",
    "    \n",
    "    def __init__(self,data, config):\n",
    "        self.time_decay_tr = data[0]\n",
    "        self.time_decay_te = data[1]\n",
    "        self.X_tr = data[2]\n",
    "        self.X_te = data[3]\n",
    "        self.X_tr_lr = data[4]\n",
    "        self.X_te_lr = data[5]\n",
    "        self.Y_train = data[6]\n",
    "        self.Y_test = data[7]\n",
    "        self.all_X = data[8]\n",
    "        self.time_decay = data[9]\n",
    "        self.newlines = data[10]\n",
    "        self.y = data[11]\n",
    "        self.categorical_vars = data[12]\n",
    "        self.paths = data[13]\n",
    "        self.config = config\n",
    "        self.channels = config['channels']\n",
    "        self.Tx = config['Tx']\n",
    "        self.n_a = config['n_a']\n",
    "        self.n_s = config['n_s']\n",
    "        self.s0 = config['s0']\n",
    "        self.s1 = config['s1']\n",
    "        self.vocab_size = config['vocab_size']\n",
    "        self.epochs = config['epochs']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.learning_rate = config['learning_rate']\n",
    "        \n",
    "    def save_weight(self,name,model):\n",
    "        model.save_weights(name)\n",
    "    \n",
    "    def load_weight(self,name):\n",
    "        self.model.load_weights(name)\n",
    "      \n",
    "    def one_step_attention(self, a, s_prev,t0):\n",
    "        repeator = RepeatVector(Tx)\n",
    "        concatenator = Concatenate(axis=-1)\n",
    "        densor1 = Dense(10, activation = \"tanh\")\n",
    "        densor2 = Dense(1, activation = \"relu\")\n",
    "        activator = Activation(self.softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "        dotor = Dot(axes = 1)\n",
    "        # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\".\n",
    "        s_prev = repeator(s_prev)\n",
    "        # Use concatenator to concatenate a and s_prev on the last axis\n",
    "        concat = concatenator([s_prev,a])\n",
    "        # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e.\n",
    "        e = densor1(concat)\n",
    "        # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies.\n",
    "        energies = densor2(e)\n",
    "        # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" \n",
    "        energies = Subtract(name='data-time')([energies,t0])\n",
    "        alphas = activator(energies)\n",
    "        # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next layer\n",
    "        context = dotor([alphas,a])\n",
    "        return context \n",
    "    \n",
    "    \n",
    "    def build_embedding_network(self, no_of_unique_cat=83, output_shape=32):\n",
    "        inputss = []\n",
    "        embeddings = []\n",
    "        for c in self.categorical_vars:\n",
    "            inputs = Input(shape=(1,),name='input_sparse_'+c)\n",
    "            #no_of_unique_cat  = data_lr[categorical_var].nunique()\n",
    "            embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "            embedding_size = int(embedding_size)\n",
    "            embedding = Embedding(no_of_unique_cat+1, embedding_size, input_length = 1)(inputs)\n",
    "            embedding = Reshape(target_shape=(embedding_size,))(embedding)\n",
    "            inputss.append(inputs)\n",
    "            embeddings.append(embedding)\n",
    "        input_numeric = Input(shape=(1,),name='input_constinuous')\n",
    "        embedding_numeric = Dense(16)(input_numeric)\n",
    "        inputss.append(input_numeric)\n",
    "        embeddings.append(embedding_numeric)\n",
    "\n",
    "        x = Concatenate()(embeddings)\n",
    "\n",
    "        x = Dense(10, activation = 'relu')(x)\n",
    "        x = Dropout(.15)(x)\n",
    "        out_control = Dense(output_shape)(x)\n",
    "        return inputss,out_control\n",
    "\n",
    "    def softmax(self,x,axis=1):\n",
    "        ndim = K.ndim(x)\n",
    "        if ndim==2:\n",
    "            return K.softmax(x)\n",
    "        elif ndim >2:\n",
    "            e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "            s = K.sum(e, axis=axis, keepdims =True)\n",
    "            return e/s\n",
    "        else:\n",
    "            raise ValueError('Cannot apply softmax to a tensor that is 1D')\n",
    "    \n",
    "    def model(self):\n",
    "        '''\n",
    "        模型初始化\n",
    "\n",
    "        '''\n",
    "        # Define the inputs of your model with a shape (Tx,)\n",
    "        # Define s0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "        input_att = Input(shape=(self.Tx, self.vocab_size), name='input_path')\n",
    "        s0 = Input(shape=(self.n_s,), name='s0')\n",
    "        s = s0\n",
    "        # input time decay data\n",
    "        t0 = Input(shape=(self.Tx,1), name='input_timeDecay')\n",
    "        t = t0\n",
    "        # Step 1: Define pre-attention LSTM.\n",
    "        a = LSTM(self.n_a,return_sequences=True)(input_att)\n",
    " \n",
    "        # Step 2: import attention model\n",
    "        context = self.one_step_attention(a,s,t)\n",
    "        c = Flatten()(context)\n",
    "        out_att = Dense(32, activation = \"sigmoid\", name='single_output')(c)\n",
    "\n",
    "        # Step 3: import embedding data for customer-ralated variables\n",
    "        input_con,out_control = self.build_embedding_network()\n",
    "        added = Add()([out_att, out_control])\n",
    "        out_all = Dense(1,activation='sigmoid')(added)\n",
    "        # Step 4: Create model instance taking three inputs and returning the list of outputs.\n",
    "        self.model = Model([input_att,s0,t0,input_con[0],\n",
    "                      input_con[1],input_con[2],input_con[3]],out_all)\n",
    "        print(self.model.summary())\n",
    "        #return self.model\n",
    "    \n",
    "    def train_model(self,save_name, loss='binary_crossentropy',opt='adam',metrics=['accuracy']):\n",
    "        self.model.compile(loss=loss,optimizer=opt,metrics=metrics)\n",
    "        self.history = self.model.fit([self.X_tr,self.s0,self.time_decay_tr,self.X_tr_lr.iloc[:,0],self.X_tr_lr.iloc[:,1],\n",
    "               self.X_tr_lr.iloc[:,2],self.X_tr_lr.iloc[:,3]\n",
    "              ], self.Y_train, epochs=self.epochs, batch_size=self.batch_size,verbose=2)\n",
    "    \n",
    "        self.save_weight(save_name,self.model)\n",
    "    \n",
    "    # model performance\n",
    "    def plot_roc_curve(self, fpr, tpr, label=None): \n",
    "        plt.plot(fpr, tpr, linewidth=2, label=label) \n",
    "        plt.plot([0, 1], [0, 1], 'k--') \n",
    "        plt.axis([0, 1, 0, 1])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "    def metric(self, y_valid,prob,cl,label=None):\n",
    "        fpr, tpr, threshold = roc_curve(y_valid, prob)\n",
    "        auc = roc_auc_score(y_valid,prob)\n",
    "        self.plot_roc_curve(fpr,tpr,label=label)\n",
    "        acc = (y_valid==cl).mean()\n",
    "        print('Accuracy: {:.3f}, AUC: {:.3f}'.format(acc,auc))\n",
    "    \n",
    "\n",
    "    def plot_loss(self):\n",
    "        ylims = range(1,self.epochs+1,10)\n",
    "        plt.plot(self.history.history['loss'],color='red',label='train loss')\n",
    "        plt.xticks(ylims)\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('train loss vs epochs')\n",
    "    def plot_acc(self):\n",
    "        ylims = range(1,self.epochs+1,10)\n",
    "        plt.plot(self.history.history['acc'],label='acc',c='r')    \n",
    "        plt.xticks(ylims)\n",
    "        plt.legend(loc=4)\n",
    "        plt.title('train acc vs epochs')\n",
    "    def auc_score_train(self,threshold):\n",
    "        prob = self.model.predict([self.X_tr,self.s0,self.time_decay_tr,self.X_tr_lr.iloc[:,0],self.X_tr_lr.iloc[:,1],\n",
    "               self.X_tr_lr.iloc[:,2],self.X_tr_lr.iloc[:,3]])\n",
    "        cl = [1 if p > threshold else 0 for p in prob]\n",
    "        print(confusion_matrix(self.Y_train,cl))\n",
    "        print(self.metric(self.Y_train,prob,cl,label='train dataset performance'))\n",
    "    def auc_score_test(self,threshold):\n",
    "        prob = self.model.predict([self.X_te,self.s1,self.time_decay_te,self.X_te_lr.iloc[:,0],self.X_te_lr.iloc[:,1],\n",
    "               self.X_te_lr.iloc[:,2],self.X_te_lr.iloc[:,3]])\n",
    "        cl = [1 if p > threshold else 0 for p in prob]\n",
    "        print(confusion_matrix(self.Y_test,cl))\n",
    "        print(self.metric(self.Y_test,prob,cl,label='test dataset performance'))  \n",
    "        \n",
    "    def test_model(self,threshold,train=False):\n",
    "        if train:\n",
    "            self.auc_score_train(threshold)\n",
    "        else:\n",
    "            self.auc_socre_test(threshold)\n",
    "            \n",
    "    # credits for different channels; as the input data for budget calculation formula\n",
    "    def attributes(self):\n",
    "        layer = self.model.layers[20]\n",
    "        m_all,_,_ = self.all_X.shape\n",
    "        self.s_all = np.zeros((m_all, self.n_s))\n",
    "        f_f = K.function([self.model.input[0],self.model.input[1],self.model.input[2]], [layer.output])\n",
    "        r=f_f([self.all_X[self.y==1],self.s_all[self.y==1],self.time_decay[self.y==1]])[0].reshape(self.all_X[self.y==1].shape[0],self.all_X[self.y==1].shape[1])\n",
    "        \n",
    "        att_f = {m:0 for m in range(1,6)}\n",
    "        att_count_f = {m:0 for m in range(1,6)}\n",
    "        chan_used = self.newlines[self.y==1]\n",
    "        for m in range(chan_used.shape[0]):\n",
    "            for n in range(chan_used.shape[1]):\n",
    "                if chan_used[m,n]!=0:\n",
    "                    att_f[chan_used[m,n]] += r[m,n]\n",
    "                    att_count_f[chan_used[m,n]] += 1\n",
    "        att_f[self.channels[0]] = att_f.pop(1)\n",
    "        att_f[self.channels[1]] = att_f.pop(2)\n",
    "        att_f[self.channels[2]] = att_f.pop(3)\n",
    "        att_f[self.channels[3]] = att_f.pop(4)\n",
    "        att_f[self.channels[4]] = att_f.pop(5)\n",
    "        \n",
    "        return att_f\n",
    "    \n",
    "    def critical_paths(self):\n",
    "        prob = self.model.predict([self.X_tr,self.s0,self.time_decay_tr,self.X_tr_lr.iloc[:,0],self.X_tr_lr.iloc[:,1],\n",
    "           self.X_tr_lr.iloc[:,2],self.X_tr_lr.iloc[:,3]])\n",
    "        cp_idx = sorted(range(len(prob)), key=lambda k: prob[k], reverse=True)\n",
    "        #print([prob[p] for p in cp_idx[0:100]])\n",
    "        cp_p = [self.paths[p] for p in cp_idx[0:100]]\n",
    "        \n",
    "        cp_p_2 = set(map(tuple, cp_p))\n",
    "        print(list(map(list,cp_p_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba79f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
